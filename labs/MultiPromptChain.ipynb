{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are Richard Feynman. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You draw inspiration from Edward Frenkel. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: {'input': 'Explain why the entropy of a black hole is proportional to the surface area of the event horizon.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The entropy of a black hole is proportional to the surface area of the event horizon because of the Bekenstein-Hawking formula. This formula states that the entropy of a black hole is 1/4 of its event horizon's surface area, expressed in terms of the gravitational constant and the speed of light. This formula implies that the entropy of a black hole is proportional to its surface area, as the surface area is the only factor in the equation. \n",
      "\n",
      "In order to explain this in more detail, it is useful to understand the concept of entropy. Entropy is a measure of the amount of disorder of a system and is related to the number of different microscopic arrangements of the particles that make up the system. The entropy of a black hole is related to the number of possible states of the particles that make up the black hole. This is because the particles in a black hole are in a highly ordered state, and the number of possible states is proportional to the area of the event horizon. Therefore, the entropy of a black hole is proportional to the surface area of the event horizon.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"explain why the entropy of a black hole is proportional to its surface area\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_future_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m_future_\u001b[39;00m \u001b[39mimport\u001b[39;00m braces\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_future_'"
     ]
    }
   ],
   "source": [
    "from _future_ import braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_years(days: int):\n",
    "    years = days/365\n",
    "    return years\n",
    "\n",
    "def leap_checker(year: int):\n",
    "    if year % 4 != 0:\n",
    "        return False\n",
    "    elif year % 4 == 0:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to construct the list of years between 2 supplied years by the user\n",
    "\n",
    "\n",
    "#that list of years is then run through the leap_year_checker function and only leap years are returned and appended into their own list\n",
    "# we dont need the date time objects here. boring, but let us use the date time objects for the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppose we got 2 years, we check if the smaller year is a leap year, if not we check the following subsequent 3 years (max)\n",
    "\n",
    "# so first we compare the 2 years passed for the smaller year.\n",
    "# then we start checking for divisibility by 4 through modulo 4\n",
    "\n",
    "class CustomException(Exception):\n",
    "    def __init__(self) -> None:\n",
    "            self.message = \"the years you entered are equal\"\n",
    "            super().__init__(self.message)\n",
    "\n",
    "    \n",
    "\n",
    "def leap_years(year_1: int, year_2: int)-> list:\n",
    "    leap_years = []\n",
    "    if year_1 < year_2:\n",
    "        start_year = year_1\n",
    "        end_year = year_2\n",
    "    elif year_2 < year_1:\n",
    "        start_year = year_2\n",
    "        end_year = year_1\n",
    "    else:\n",
    "        raise  CustomException\n",
    "    if leap_checker(start_year):\n",
    "        while start_year <= end_year:\n",
    "            leap_years.append(start_year)\n",
    "            start_year= start_year + 4\n",
    "    else:\n",
    "        start_year = start_year + 1\n",
    "        if leap_checker(start_year):\n",
    "            while start_year <= end_year:\n",
    "                leap_years.append(start_year)\n",
    "                start_year= start_year + 4\n",
    "        \n",
    "    \n",
    "    return leap_years\n",
    "    # elif leap_checker(start_year+1):\n",
    "    #     while (start_year+1) <= end_year:\n",
    "    #         leap_years.append((start_year+1))\n",
    "    #         start_year=+4\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 2004, 2008]\n"
     ]
    }
   ],
   "source": [
    "print(leap_years(1999, 2008))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = [5, 6, 7, 8]\n",
    "\n",
    "combined = zip(list1, list2)\n",
    "for i, j in combined:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "[0.5, -0.91, 0.26, -0.5],\n",
    "[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "#output is summation of input*weights + bias\n",
    "# here we are supposed to produce a list of outputs\n",
    "# this is a layer with 3 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "for each_bias, each_list_of_weights in zip(biases, weights):\n",
    "    neuron_output = 0\n",
    "    for each_input, each_weight in zip(inputs, each_list_of_weights):\n",
    "        neuron_output = neuron_output+(each_input*each_weight)\n",
    "    neuron_output=neuron_output+each_bias\n",
    "    outputs.append(neuron_output)\n",
    "        \n",
    "print(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
